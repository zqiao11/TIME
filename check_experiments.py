#!/usr/bin/env python3
"""
æ£€æŸ¥ output/results ä¸­æ¯ä¸ªæ¨¡å‹æ˜¯å¦è¿è¡Œäº† datasets.yaml ä¸­å®šä¹‰çš„å…¨éƒ¨å®éªŒã€‚
"""

import os
import yaml
from pathlib import Path
from collections import defaultdict


def load_expected_experiments(yaml_path: str) -> set:
    """
    ä» datasets.yaml åŠ è½½æ‰€æœ‰é¢„æœŸçš„ (dataset, freq, term) ç»„åˆã€‚
    """
    with open(yaml_path, 'r') as f:
        config = yaml.safe_load(f)

    experiments = set()
    datasets = config.get('datasets', {})

    for dataset_freq, settings in datasets.items():
        # dataset_freq æ ¼å¼ä¸º "dataset_name/freq"
        parts = dataset_freq.split('/')
        if len(parts) != 2:
            print(f"è­¦å‘Š: æ— æ³•è§£æ '{dataset_freq}'ï¼Œè·³è¿‡")
            continue

        dataset_name, freq = parts

        # è·å–æ‰€æœ‰ term (short, medium, long)
        for term in ['short', 'medium', 'long']:
            if term in settings:
                experiments.add((dataset_name, freq, term))

    return experiments


def get_completed_experiments(model_path: Path) -> set:
    """
    è·å–æ¨¡å‹å·²å®Œæˆçš„å®éªŒ (dataset, freq, term) ç»„åˆã€‚
    æ£€æŸ¥æ˜¯å¦å­˜åœ¨ results.json æˆ– metrics.json æ–‡ä»¶ã€‚
    """
    completed = set()

    if not model_path.exists():
        return completed

    # éå† dataset ç›®å½•
    for dataset_dir in model_path.iterdir():
        if not dataset_dir.is_dir():
            continue
        dataset_name = dataset_dir.name

        # éå† freq ç›®å½•
        for freq_dir in dataset_dir.iterdir():
            if not freq_dir.is_dir():
                continue
            freq = freq_dir.name

            # éå† term ç›®å½•
            for term_dir in freq_dir.iterdir():
                if not term_dir.is_dir():
                    continue
                term = term_dir.name

                # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœæ–‡ä»¶ï¼ˆresults.json æˆ– metrics.jsonï¼‰
                results_file = term_dir / 'results.json'
                metrics_file = term_dir / 'metrics.json'

                if results_file.exists() or metrics_file.exists():
                    completed.add((dataset_name, freq, term))
                else:
                    # å¦‚æœç›®å½•å­˜åœ¨ä½†æ²¡æœ‰ç»“æœæ–‡ä»¶ï¼Œä¹Ÿè®¤ä¸ºå®Œæˆï¼ˆå¯èƒ½æ˜¯å…¶ä»–æ ¼å¼ï¼‰
                    # æ£€æŸ¥ç›®å½•æ˜¯å¦æœ‰ä»»ä½•æ–‡ä»¶
                    has_files = any(term_dir.iterdir())
                    if has_files:
                        completed.add((dataset_name, freq, term))

    return completed


def main():
    # è·¯å¾„è®¾ç½®
    base_dir = Path(__file__).parent
    yaml_path = base_dir / 'src/timebench/config/datasets.yaml'
    results_dir = base_dir / 'output/results'

    # åŠ è½½é¢„æœŸå®éªŒ
    print("=" * 70)
    print("æ£€æŸ¥å®éªŒå®ŒæˆçŠ¶æ€")
    print("=" * 70)

    expected = load_expected_experiments(yaml_path)
    print(f"\nğŸ“‹ datasets.yaml ä¸­å®šä¹‰çš„å®éªŒæ€»æ•°: {len(expected)}")

    # æŒ‰ dataset/freq åˆ†ç»„æ˜¾ç¤º
    by_dataset_freq = defaultdict(list)
    for dataset, freq, term in sorted(expected):
        by_dataset_freq[(dataset, freq)].append(term)

    print(f"   æ¶µç›– {len(by_dataset_freq)} ä¸ª dataset/freq ç»„åˆ")

    # è·å–æ‰€æœ‰æ¨¡å‹
    if not results_dir.exists():
        print(f"\nâŒ ç»“æœç›®å½•ä¸å­˜åœ¨: {results_dir}")
        return

    models = sorted([d.name for d in results_dir.iterdir() if d.is_dir()])
    print(f"\nğŸ¤– å‘ç° {len(models)} ä¸ªæ¨¡å‹: {', '.join(models)}")

    # æ£€æŸ¥æ¯ä¸ªæ¨¡å‹
    print("\n" + "=" * 70)
    print("å„æ¨¡å‹å®ŒæˆçŠ¶æ€")
    print("=" * 70)

    all_complete = []
    incomplete = []

    for model in models:
        model_path = results_dir / model
        completed = get_completed_experiments(model_path)
        missing = expected - completed

        completion_rate = len(completed) / len(expected) * 100 if expected else 0

        if not missing:
            all_complete.append(model)
            print(f"\nâœ… {model}: {len(completed)}/{len(expected)} ({completion_rate:.1f}%) - å…¨éƒ¨å®Œæˆ!")
        else:
            incomplete.append((model, missing))
            print(f"\nâŒ {model}: {len(completed)}/{len(expected)} ({completion_rate:.1f}%) - ç¼ºå°‘ {len(missing)} ä¸ªå®éªŒ")

            # æŒ‰ dataset/freq åˆ†ç»„æ˜¾ç¤ºç¼ºå¤±çš„å®éªŒ
            missing_by_df = defaultdict(list)
            for dataset, freq, term in sorted(missing):
                missing_by_df[(dataset, freq)].append(term)

            for (dataset, freq), terms in sorted(missing_by_df.items()):
                print(f"   - {dataset}/{freq}: {', '.join(sorted(terms))}")

    # æ±‡æ€»
    print("\n" + "=" * 70)
    print("æ±‡æ€»")
    print("=" * 70)
    print(f"âœ… å®Œæˆå…¨éƒ¨å®éªŒçš„æ¨¡å‹ ({len(all_complete)}): {', '.join(all_complete) if all_complete else 'æ— '}")
    print(f"âŒ æœ‰ç¼ºå¤±å®éªŒçš„æ¨¡å‹ ({len(incomplete)}): {', '.join([m for m, _ in incomplete]) if incomplete else 'æ— '}")

    # å¦‚æœéœ€è¦ï¼Œç”Ÿæˆç¼ºå¤±å®éªŒçš„è¯¦ç»†æŠ¥å‘Š
    if incomplete:
        print("\n" + "=" * 70)
        print("ç¼ºå¤±å®éªŒè¯¦ç»†åˆ—è¡¨")
        print("=" * 70)
        for model, missing in incomplete:
            print(f"\n### {model} ###")
            for dataset, freq, term in sorted(missing):
                print(f"  {dataset}/{freq}/{term}")


if __name__ == '__main__':
    main()
